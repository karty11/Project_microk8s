# Disable built-in PostgreSQL (it's failing)
postgresql:
  enabled: false

# Keep Redis enabled (Airflow uses it for Celery/triggerer)
redis:
  enabled: true

# Use MySQL as the Airflow metadata DB
externalDatabase:
  type: mysql
  host: mysql-service.devproject.svc.cluster.local
  port: 3306
  user: root
  password: "Test@123"        # ✅ quotes prevent YAML parser issues
  database: bankappdb

executor: LocalExecutor
replicaCount: 1

web:
  enabled: true
  service:
    type: ClusterIP
  defaultUser:
    enabled: true
    username: admin
    password: admin

# Mount your DAGs
volumes:
  - name: demo-dags
    hostPath:
      path: /home/ubuntu/Project_microk8s/dags
      type: Directory
volumeMounts:
  - name: demo-dags
    mountPath: /opt/airflow/dags

extraEnv:
  - name: MINIO_ENDPOINT
    value: "http://demo-minio.minio.svc.cluster.local:9000"
  - name: MINIO_BUCKET
    value: "app-data"
  - name: MYSQL_CONN_ID
    value: "app_mysql"

envFrom:
  - secretRef:
      name: minio-creds

connections:
  - id: app_mysql
    type: mysql
    host: mysql-service.devproject.svc.cluster.local
    login: root
    password: "Test@123"       # ✅ same MySQL creds, quoted for safety
    schema: bankappdb
    port: 3306

extraPipPackages:
  - apache-airflow-providers-mysql
  - boto3
  - pandas

resources:
  requests:
    cpu: 100m
    memory: 256Mi
  limits:
    cpu: 500m
    memory: 512Mi
